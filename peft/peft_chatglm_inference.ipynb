{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5bde60-1899-461d-8083-3ee04ac7c099",
   "metadata": {},
   "source": [
    "# 模型推理 - 使用 QLoRA 微调后的 ChatGLM3-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3292b88c-91f0-48d2-91a5-06b0830c7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# 定义全局变量和参数\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'  # 模型ID或本地路径\n",
    "peft_model_path = f\"models/demo/{model_name_or_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f81454c-24b2-4072-ab05-b25f9b120ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960e26be3cc54a609b90778ad374d001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdgc\\anaconda3\\envs\\transformers\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kdgc\\.cache\\huggingface\\hub\\models--THUDM--chatglm3-6b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d50b2f8aca4600a3b633a418b01ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_chatglm.py:   0%|          | 0.00/2.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
      "- configuration_chatglm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864dbd5ee5544f81822afe4c3b65dfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_chatglm.py:   0%|          | 0.00/55.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8edc5211b8c42af8685d25dc506beed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "quantization.py:   0%|          | 0.00/14.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
      "- quantization.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
      "- modeling_chatglm.py\n",
      "- quantization.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f89dba9a02a4d2e9c07449ff1f968ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/21.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32db065bce84718a693fbeb8d29d39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66011cbc50e43b083b5b556037284bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00007.safetensors:   0%|          | 0.00/1.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad16f423c059438b8364730264c711ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00007.safetensors:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f871016bd1405996913043b19cb9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00007.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbdd8ea8bdf49fa97b8c8c78801e175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00007.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2446ba84ca4e5299f869c35964f74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00007.safetensors:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4e51d7466c4b219a164fa0506ed807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00007.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b7b705e5a54383920c0c14caf3422d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00007.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f347d31fcb5463298d6fb82456faf71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGLMForConditionalGeneration(\n",
       "  (transformer): ChatGLMModel(\n",
       "    (embedding): Embedding(\n",
       "      (word_embeddings): Embedding(65024, 4096)\n",
       "    )\n",
       "    (rotary_pos_emb): RotaryEmbedding()\n",
       "    (encoder): GLMTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x GLMBlock(\n",
       "          (input_layernorm): RMSNorm()\n",
       "          (self_attention): SelfAttention(\n",
       "            (query_key_value): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
       "            (core_attention): CoreAttention(\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (post_attention_layernorm): RMSNorm()\n",
       "          (mlp): MLP(\n",
       "            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
       "            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layernorm): RMSNorm()\n",
       "    )\n",
       "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = PeftConfig.from_pretrained(peft_model_path)\n",
    "\n",
    "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                              bnb_4bit_quant_type='nf4',\n",
    "                              bnb_4bit_use_double_quant=True,\n",
    "                              bnb_4bit_compute_dtype=torch.float32)\n",
    "\n",
    "base_model = AutoModel.from_pretrained(config.base_model_name_or_path,\n",
    "                                       quantization_config=q_config,\n",
    "                                       trust_remote_code=True,\n",
    "                                       device_map='auto')\n",
    "base_model.requires_grad_(False)\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b3659-d644-4232-8af1-f092e733bf40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d23e720-dee1-4b43-a298-0cbe1d8ad11d",
   "metadata": {},
   "source": [
    "## 微调前后效果对比\n",
    "\n",
    "### ChatGLM-6B\n",
    "\n",
    "```\n",
    "输入：\n",
    "\n",
    "类型#裙*版型#显瘦*风格#文艺*风格#简约*图案#印花*图案#撞色*裙下摆#压褶*裙长#连衣裙*裙领型#圆领\n",
    "\n",
    "ChatGLM-6B 微调前输出：\n",
    "\n",
    "* 版型：修身\n",
    "* 显瘦：True\n",
    "* 风格：文艺\n",
    "* 简约：True\n",
    "* 图案：印花\n",
    "* 撞色：True\n",
    "* 裙下摆：直筒或微喇\n",
    "* 裙长：中长裙\n",
    "* 连衣裙：True\n",
    "\n",
    "ChatGLM-6B 微调后输出：\n",
    "\n",
    "一款简约而不简单的连衣裙，采用撞色的印花点缀，打造文艺气息，简约的圆领，修饰脸型。衣袖和裙摆的压褶，增添设计感，修身的版型，勾勒出窈窕的身材曲线。\n",
    "```\n",
    "\n",
    "### ChatGLM2-6B\n",
    "\n",
    "```\n",
    "输入：\n",
    "类型#裙*版型#显瘦*风格#文艺*风格#简约*图案#印花*图案#撞色*裙下摆#压褶*裙长#连衣裙*裙领型#圆领\n",
    "\n",
    "微调前：\n",
    "这款裙子,版型显瘦,采用简约文艺风格,图案为印花和撞色设计,裙下摆为压褶裙摆,裙长为连衣裙,适合各种场合穿着,让你舒适自在。圆领设计,优雅清新,让你在任何场合都充满自信。如果你正在寻找一款舒适、时尚、优雅的裙子,不妨 考虑这款吧!\n",
    "\n",
    "微调后: \n",
    "这款连衣裙简约的设计，撞色印花点缀，丰富了视觉，上身更显时尚。修身的版型，贴合身形，穿着舒适不束缚。圆领的设计，露出精致锁骨，尽显女性优雅气质。下摆压褶的设计，增添立体感，行走间更显飘逸。前短后长的设计，显 得身材比例更加完美。文艺的碎花设计，更显精致。\n",
    "```\n",
    "\n",
    "### ChatGLM3-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d7757a4-7d1f-488f-8d80-b73dfa4863d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：\n",
      "类型#裙*版型#显瘦*风格#文艺*风格#简约*图案#印花*图案#撞色*裙下摆#压褶*裙长#连衣裙*裙领型#圆领\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884a8997a42a4e6192dd2b5e6195ac3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3988e7ef32c348bea6865c92ac6ba32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenization_chatglm.py:   0%|          | 0.00/13.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
      "- tokenization_chatglm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33807f0c9bf94d9688ec341ed44d218b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/1.02M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b8ef4800f541828f186be7d6d1f550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n"
     ]
    }
   ],
   "source": [
    "input_text = '类型#裙*版型#显瘦*风格#文艺*风格#简约*图案#印花*图案#撞色*裙下摆#压褶*裙长#连衣裙*裙领型#圆领'\n",
    "print(f'输入：\\n{input_text}')\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d30fce1-e01f-4303-aa55-ed004eaa22a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdgc\\anaconda3\\envs\\transformers\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kdgc\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm3-6b\\6f3b58ec10f088978ae174398f9d20b6dfc71552\\modeling_chatglm.py:226: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  context_layer = torch.nn.functional.scaled_dot_product_attention(query_layer, key_layer, value_layer,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGLM3-6B 微调前：\n",
      "你好，根据你提供的关键词，我为你找到了以下内容：\n",
      "\n",
      "1. 裙：这是一种长度及下摆宽度的服装单品，通常由轻薄的面料制成，可以在 walking、舞蹈等场合穿着。\n",
      "\n",
      "2. 显瘦：这是一种服装设计的原则，旨在使穿着者的身材显得更加苗条和修长。\n",
      "\n",
      "3. 文艺风格：这是一种强调艺术和文化气息的服装风格，通常包括色彩柔和、图案复杂、材质柔软的服装。\n",
      "\n",
      "4. 简约风格：这是一种简洁、不拖泥带水的设计风格，强调的是简单、纯粹和干净。\n",
      "\n",
      "5. 印花：这是一种图案设计，通常使用花卉、几何图形等元素，可以在服装、家居用品等地方看到。\n",
      "\n",
      "6. 撞色：这是一种色彩搭配方式，通过在服装上使用对比色来制造视觉冲击。\n",
      "\n",
      "7. 裙下摆：这是指裙子底部的装饰，可以是褶皱、荷叶边、燃料等。\n",
      "\n",
      "8. 压褶：这是一种装饰性技术，通常用于在面料上形成一系列的褶皱，使裙子更具有立体感和优雅感。\n",
      "\n",
      "9. 裙长：这是指裙子的长度，可以是短裙、中裙、长裙等。\n",
      "\n",
      "10. 连衣裙：这是一种单一片式的服装，通常由上身为衣、下身为裙组成，适合各种场合穿着。\n",
      "\n",
      "11. 裙领型：这是指裙子的领口形状，可以是圆领、V领、U领等。\n",
      "\n",
      "希望这些信息对你有所帮助！\n"
     ]
    }
   ],
   "source": [
    "response, history = base_model.chat(tokenizer=tokenizer, query=input_text)\n",
    "print(f'ChatGLM3-6B 微调前：\\n{response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b5a770-baef-4697-bb71-6088e3a43d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGLM3-6B 微调后: \n",
      "裙身采用撞色印花设计，简洁大方，彰显文艺气息。简约圆领设计，衬托出优美的颈部线条，修饰脸型。裙摆采用压褶设计，修饰腿型，优雅大方。\n"
     ]
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "response, history = model.chat(tokenizer=tokenizer, query=input_text)\n",
    "print(f'ChatGLM3-6B 微调后: \\n{response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf454e0-f0f5-4fb0-ab90-83e9615f132a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
